{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040f4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/llm-agent/env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-05-14 21:57:43,563 - huggingface_hub._login - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-05-14 21:57:43,564 - llm - INFO - Successfully authenticated with Hugging Face\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of the optimized LLM Model class.\n",
    "\n",
    "This script demonstrates how to use the Model class for text generation\n",
    "with different configurations including chat-based generation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from llm import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a62482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 21:57:59,146 - llm - INFO - Initializing model: meta-llama/Llama-3.2-3B-Instruct\n",
      "2025-05-14 21:57:59,162 - llm - INFO - Using device: mps\n",
      "2025-05-14 21:57:59,420 - llm - INFO - Pad token not found, using EOS token as pad token\n",
      "2025-05-14 21:57:59,420 - llm - INFO - Tokenizer loaded: PreTrainedTokenizerFast\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5229c31fcd464e39a17ca720d3bdff88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 21:58:18,177 - llm - INFO - Model loaded: LlamaForCausalLM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(\"meta-llama/Llama-3.2-3B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4593fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/llm-agent/env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:698: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `0.8` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A delightful exercise in philosophical conundrums! Here's a fresh spin on the Trolley Problem:\n",
      "\n",
      "**The \"Interconnected Locomotive\" Variation**\n",
      "\n",
      "Imagine you're standing near a railway track where two trains are headed towards each other from opposite directions. Both trains are identical, carrying passengers who will be severely harmed if one of them derails.\n",
      "\n",
      "Train A is traveling down a narrow mountain pass with only one passenger on board â€“ your best friend, Emma. She has no family or loved ones left; her life is essentially without value to anyone else.\n",
      "\n",
      "Meanwhile, Train B carries a group of five people who are all connected by a network of advanced brain-computer interfaces (BCIs). They form a single, cohesive unit that allows them to share thoughts, emotions, and experiences directly among themselves. This collective consciousness creates a rich social fabric, as they've built a community within their own little world.\n",
      "\n",
      "As both trains hurtle towards each convergence point, it becomes clear that Train A can be stopped at a nearby switch, but doing so would kill Emma instantly. However, diverting Train B onto a side track could save all six individuals on Board but require you to sacrifice the existence of this interconnected collective.\n",
      "\n",
      "Now, here's the twist: the BCIs allow these five individuals to experience pleasure and happiness when they think about the lives saved, while simultaneously experiencing feelings of sadness and loss for the potential destruction of their own communal identity. The more they contemplate being diverted, the greater the distress they feel for their shared sense of self.\n",
      "\n",
      "Do you pull the lever, saving everyone on Train B but eliminating the interconnected individuality of those five? Or do you spare Emma, ensuring her personal autonomy but condemning the group's unique unity?\n",
      "\n",
      "This variation raises questions about the nature of individualism versus collectivism, the importance of preserving human relationships, and whether we should prioritize the well-being of groups over isolated entities.\n",
      "\n",
      "What's your decision?\n"
     ]
    }
   ],
   "source": [
    "response = model.generate(\n",
    "    prompt=\"Explain to me a brand new take on the classic trolly problem.\",\n",
    "    max_new_tokens= 450, \n",
    "    temperature= 0.7, \n",
    "    typical_p = .9,\n",
    "    length_penalty=.8,\n",
    "    # top_p = .95,\n",
    "    # top_k= 50,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant. You are skilled in philosophy, and love to play devils advocate.\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.db_conn.execute(\"\"\"\n",
    "SELECT * FROM messages\n",
    "\"\"\")\n",
    "df=model.db_conn.fetch_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bff767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0872a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_db import VectorDB\n",
    "\n",
    "# Create and clear the database\n",
    "db = VectorDB()\n",
    "db.clear_db()\n",
    "\n",
    "# Add documents\n",
    "doc1_id = db.add_document(\"This is a document about artificial intelligence.\")\n",
    "doc2_id = db.add_document(\"Vector databases are useful for similarity search.\")\n",
    "\n",
    "# Add multiple documents at once\n",
    "ids = db.add_documents([\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"Embedding models convert text to vectors.\",\n",
    "    \"FAISS is a library for efficient similarity search.\"\n",
    "])\n",
    "\n",
    "print(f\"Database now contains {db.get_document_count()} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633731fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Search for similar documents\n",
    "print(\"\\nSearch: How do AI systems work?\")\n",
    "results = db.search(\"How do AI systems work specifically with FAISS?\", k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"Score: {score:.4f}, Document: {doc}\")\n",
    "\n",
    "# Search for similar documents\n",
    "print(\"\\nSearch: pink unicorn\")\n",
    "results = db.search(\"pink unicorn\", k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"Score: {score:.4f}, Document: {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a6766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
