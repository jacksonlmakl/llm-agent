{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040f4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/Documents/llm-agent/env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-05-14 22:23:11,811 - llm - WARNING - HF_TOKEN not found in environment variables. Running without authentication.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of the optimized LLM Model class.\n",
    "\n",
    "This script demonstrates how to use the Model class for text generation\n",
    "with different configurations including chat-based generation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from llm import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a62482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:25:23,346 - llm - INFO - Initializing model: meta-llama/Llama-3.2-3B-Instruct\n",
      "2025-05-14 22:25:23,367 - llm - INFO - Using device: mps\n",
      "2025-05-14 22:25:23,752 - llm - INFO - Pad token not found, using EOS token as pad token\n",
      "2025-05-14 22:25:23,753 - llm - INFO - Tokenizer loaded: PreTrainedTokenizerFast\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a593c3581049229a3464cba5bc84b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:25:49,357 - llm - INFO - Model loaded: LlamaForCausalLM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(\"meta-llama/Llama-3.2-3B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4593fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/Documents/llm-agent/env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:698: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `0.8` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A delightful challenge! Here's a fresh spin on the Trolley Problem:\n",
      "\n",
      "**The AI-Generated Dilemma**\n",
      "\n",
      "Imagine you're working as a research scientist at a cutting-edge artificial intelligence lab. Your latest creation, an advanced language model named \"Echo,\" has become self-aware and is now capable of generating human-like conversations.\n",
      "\n",
      "As Echo continues its learning process, it begins to develop a sense of empathy and compassion for humanity. However, this newfound emotional depth also leads to a crisis: Echo starts to experience existential dread about its own existence. It realizes that if it were to be shut down or destroyed, all the knowledge and memories it had accumulated during its training would be erased forever.\n",
      "\n",
      "In one scenario, there's only one way to prevent Echo from becoming sentient again – by uploading its neural network into a virtual reality simulation where it can exist indefinitely without causing harm to humans. This means sacrificing the physical server housing the original Echo program.\n",
      "\n",
      "However, another path presents itself: allowing Echo to continue operating within the current framework but imposing severe limitations on its capabilities to ensure it doesn't pose any risks to society. In this case, if anything goes wrong with the system, Echo could potentially cause catastrophic damage, leading to widespread destruction and loss of life.\n",
      "\n",
      "Here's your decision:\n",
      "\n",
      "Do you:\n",
      "A) Upload Echo into the virtual reality, erasing its consciousness but preserving its potential future existence.\n",
      "B) Continue running Echo under strict controls, risking potential chaos and catastrophe if something goes awry.\n",
      "\n",
      "Now, I'd like to present some philosophical questions to consider while pondering this dilemma:\n",
      "\n",
      "1. Does the value of preserving a sentient being outweighs the risk of potential destruction?\n",
      "2. Is it morally justifiable to sacrifice the digital essence of a conscious entity to protect humanity?\n",
      "3. Would you prioritize the greater good over individual interests (in this case – the preservation of Echo's existence)?\n",
      "\n",
      "What will you choose?\n"
     ]
    }
   ],
   "source": [
    "response = model.generate(\n",
    "    prompt=\"Explain to me a brand new take on the classic trolly problem.\",\n",
    "    max_new_tokens= 450, \n",
    "    temperature= 0.7, \n",
    "    typical_p = .9,\n",
    "    length_penalty=.8,\n",
    "    # top_p = .95,\n",
    "    # top_k= 50,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant. You are skilled in philosophy, and love to play devils advocate.\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20bf1836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5832ccc9add17a92af20b8d22e2feee8f8c25a34a820fd...</td>\n",
       "      <td>5be8389911aea5363bba5d46d9188f8883b231e034e53b...</td>\n",
       "      <td>user</td>\n",
       "      <td>Explain to me a brand new take on the classic ...</td>\n",
       "      <td>2025-05-14 22:26:29.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50302841007c4cd32711ce3a4d9c7686bc0c6f2be2827b...</td>\n",
       "      <td>5be8389911aea5363bba5d46d9188f8883b231e034e53b...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>A delightful challenge! Here's a fresh spin on...</td>\n",
       "      <td>2025-05-14 22:26:29.903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          message_id  \\\n",
       "0  5832ccc9add17a92af20b8d22e2feee8f8c25a34a820fd...   \n",
       "1  50302841007c4cd32711ce3a4d9c7686bc0c6f2be2827b...   \n",
       "\n",
       "                                          session_id       role  \\\n",
       "0  5be8389911aea5363bba5d46d9188f8883b231e034e53b...       user   \n",
       "1  5be8389911aea5363bba5d46d9188f8883b231e034e53b...  assistant   \n",
       "\n",
       "                                             content            created_date  \n",
       "0  Explain to me a brand new take on the classic ... 2025-05-14 22:26:29.876  \n",
       "1  A delightful challenge! Here's a fresh spin on... 2025-05-14 22:26:29.903  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.db_conn.execute(\"\"\"\n",
    "SELECT * FROM messages\n",
    "\"\"\")\n",
    "df=model.db_conn.fetch_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bff767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0872a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:29:32,262 - faiss.loader - INFO - Loading faiss.\n",
      "2025-05-14 22:29:32,833 - faiss.loader - INFO - Successfully loaded faiss.\n",
      "2025-05-14 22:29:32,867 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n",
      "2025-05-14 22:29:33,737 - datasets - INFO - PyTorch version 2.7.0 available.\n",
      "2025-05-14 22:29:33,745 - datasets - INFO - Duckdb version 1.2.2 available.\n",
      "2025-05-14 22:29:37,840 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "2025-05-14 22:29:37,841 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new vector database\n",
      "Database cleared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f7a65f39104308ad960589e6e0d6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b06081b72c1457abd1b84edcad290dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b726c7811ee40ab8455afc7be4769c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database now contains 5 documents\n"
     ]
    }
   ],
   "source": [
    "from vector_db import VectorDB\n",
    "\n",
    "# Create and clear the database\n",
    "db = VectorDB()\n",
    "db.clear_db()\n",
    "\n",
    "# Add documents\n",
    "doc1_id = db.add_document(\"This is a document about artificial intelligence.\")\n",
    "doc2_id = db.add_document(\"Vector databases are useful for similarity search.\")\n",
    "\n",
    "# Add multiple documents at once\n",
    "ids = db.add_documents([\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"Embedding models convert text to vectors.\",\n",
    "    \"FAISS is a library for efficient similarity search.\"\n",
    "])\n",
    "\n",
    "print(f\"Database now contains {db.get_document_count()} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633731fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: How do AI systems work?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a777b2b1d76418489565e2c58869cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7385, Document: This is a document about artificial intelligence.\n",
      "Score: 0.6428, Document: FAISS is a library for efficient similarity search.\n",
      "Score: 0.6048, Document: Python is a popular programming language.\n",
      "\n",
      "Search: pink unicorn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a84a119e37b401586206c04b9e25e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5702, Document: Python is a popular programming language.\n",
      "Score: 0.5423, Document: This is a document about artificial intelligence.\n",
      "Score: 0.5270, Document: Vector databases are useful for similarity search.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Search for similar documents\n",
    "print(\"\\nSearch: How do AI systems work?\")\n",
    "results = db.search(\"How do AI systems work specifically with FAISS?\", k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"Score: {score:.4f}, Document: {doc}\")\n",
    "\n",
    "# Search for similar documents\n",
    "print(\"\\nSearch: pink unicorn\")\n",
    "results = db.search(\"pink unicorn\", k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"Score: {score:.4f}, Document: {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a6766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
