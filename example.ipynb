{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040f4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/Documents/llm-agent/env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-05-14 22:53:59,177 - llm - WARNING - HF_TOKEN not found in environment variables. Running without authentication.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of the optimized LLM Model class.\n",
    "\n",
    "This script demonstrates how to use the Model class for text generation\n",
    "with different configurations including chat-based generation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from llm import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a62482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:53:59,185 - llm - INFO - Initializing model: meta-llama/Llama-3.2-3B-Instruct\n",
      "2025-05-14 22:53:59,201 - llm - INFO - Using device: mps\n",
      "2025-05-14 22:53:59,568 - llm - INFO - Pad token not found, using EOS token as pad token\n",
      "2025-05-14 22:53:59,568 - llm - INFO - Tokenizer loaded: PreTrainedTokenizerFast\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9853eb3ea92400b96af0e41c0928322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:54:09,990 - llm - INFO - Model loaded: LlamaForCausalLM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(\"meta-llama/Llama-3.2-3B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4593fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/Documents/llm-agent/env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:698: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `0.8` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Trolley Problem - a timeless conundrum that continues to spark debate among philosophers, ethicists, and thought experiment enthusiasts alike.\n",
      "\n",
      "Here's my attempt at offering a fresh spin:\n",
      "\n",
      "**\"The Multiverse Trolley Dilemma\"**\n",
      "\n",
      "Imagine you're standing by a futuristic train track with multiple parallel universes branching out from it. Each universe represents a different possible outcome of every decision made throughout history. The train is hurtling towards a fork in the tracks, where five sentient beings (from various dimensions) will soon be trapped, unable to move or communicate with each other.\n",
      "\n",
      "Suddenly, one of these beings – let's call her \"Echo,\" who exists only in your own dimension – stands on the platform, frantically trying to warn others about an impending catastrophe. However, there isn't enough time for anyone else to react before the train approaches.\n",
      "\n",
      "Now, here's where things get interesting. In this multiverse scenario, every action taken would create a ripple effect, potentially saving some lives while condemning others across alternate realities. Your options are limited:\n",
      "\n",
      "A) Pull the lever, diverting the train onto a side track where Echo resides, ensuring she survives but killing everyone else in all adjacent dimensions.\n",
      "B) Leave the lever alone, allowing the original course of events to unfold, resulting in catastrophic consequences for many, including Echo.\n",
      "\n",
      "In this revised version, we've added several layers of complexity:\n",
      "\n",
      "* Every choice creates a new branch in the multiverse tree, leading to unpredictable outcomes.\n",
      "* Some individuals exist solely because their existence depends on our actions; they have no inherent value or rights outside of our consideration.\n",
      "* Decisions now carry implications not just within your immediate reality but also across countless parallel worlds.\n",
      "\n",
      "This updated twist forces us to confront questions like:\n",
      "\n",
      "1. Do we prioritize individual lives over collective well-being?\n",
      "2. Can we justify sacrificing certain lives if doing so ensures the survival of another being in another universe?\n",
      "3. Is our moral framework robust enough to handle the infinite possibilities created by such choices?\n",
      "\n",
      "Which option do you choose?\n"
     ]
    }
   ],
   "source": [
    "response = model.generate(\n",
    "    prompt=\"Explain to me a brand new take on the classic trolly problem.\",\n",
    "    max_new_tokens= 450, \n",
    "    temperature= 0.7, \n",
    "    typical_p = .9,\n",
    "    length_penalty=.8,\n",
    "    # top_p = .95,\n",
    "    # top_k= 50,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant. You are skilled in philosophy, and love to play devils advocate.\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20bf1836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d17ec2e35b786f898552e2eb2796e7ec7a433941cfcda3...</td>\n",
       "      <td>a22401dea2116e0ac75beb9a34d827ab85ef60f0696d84...</td>\n",
       "      <td>user</td>\n",
       "      <td>Explain to me a brand new take on the classic ...</td>\n",
       "      <td>2025-05-14 22:46:14.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231fcd42a089dabde51d921cfe92d11d150d286d903b2b...</td>\n",
       "      <td>a22401dea2116e0ac75beb9a34d827ab85ef60f0696d84...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>The Trolley Problem - a thought-provoking conu...</td>\n",
       "      <td>2025-05-14 22:46:14.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c8b300b09074336bde8431004d0ebf3b261d7fd604e32c...</td>\n",
       "      <td>2c1d65522d9e890e357a8628a44314b8954acbc18ec5c1...</td>\n",
       "      <td>user</td>\n",
       "      <td>Explain to me a brand new take on the classic ...</td>\n",
       "      <td>2025-05-14 22:54:52.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1e7a4ae3457a720e796db8936a583f498431afd529afe...</td>\n",
       "      <td>2c1d65522d9e890e357a8628a44314b8954acbc18ec5c1...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>The Trolley Problem - a timeless conundrum tha...</td>\n",
       "      <td>2025-05-14 22:54:52.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          message_id  \\\n",
       "0  d17ec2e35b786f898552e2eb2796e7ec7a433941cfcda3...   \n",
       "1  231fcd42a089dabde51d921cfe92d11d150d286d903b2b...   \n",
       "2  c8b300b09074336bde8431004d0ebf3b261d7fd604e32c...   \n",
       "3  a1e7a4ae3457a720e796db8936a583f498431afd529afe...   \n",
       "\n",
       "                                          session_id       role  \\\n",
       "0  a22401dea2116e0ac75beb9a34d827ab85ef60f0696d84...       user   \n",
       "1  a22401dea2116e0ac75beb9a34d827ab85ef60f0696d84...  assistant   \n",
       "2  2c1d65522d9e890e357a8628a44314b8954acbc18ec5c1...       user   \n",
       "3  2c1d65522d9e890e357a8628a44314b8954acbc18ec5c1...  assistant   \n",
       "\n",
       "                                             content            created_date  \n",
       "0  Explain to me a brand new take on the classic ... 2025-05-14 22:46:14.361  \n",
       "1  The Trolley Problem - a thought-provoking conu... 2025-05-14 22:46:14.389  \n",
       "2  Explain to me a brand new take on the classic ... 2025-05-14 22:54:52.848  \n",
       "3  The Trolley Problem - a timeless conundrum tha... 2025-05-14 22:54:52.852  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.db_conn.execute(\"\"\"\n",
    "SELECT * FROM messages\n",
    "\"\"\")\n",
    "df=model.db_conn.fetch_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bff767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0872a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:54:52,915 - faiss.loader - INFO - Loading faiss.\n",
      "2025-05-14 22:54:53,003 - faiss.loader - INFO - Successfully loaded faiss.\n",
      "2025-05-14 22:54:53,010 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n",
      "2025-05-14 22:54:53,160 - datasets - INFO - PyTorch version 2.7.0 available.\n",
      "2025-05-14 22:54:53,162 - datasets - INFO - Duckdb version 1.2.2 available.\n",
      "2025-05-14 22:54:53,448 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "2025-05-14 22:54:53,448 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing database with 5 documents\n",
      "Database cleared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ba3dddb3764556b3b6028433d571c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a2276188154555bd2aec5636354bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a029454b168944269e04a5cf0cd7b037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vector_db import VectorDB\n",
    "\n",
    "# Create and clear the database\n",
    "db = VectorDB()\n",
    "db.clear_db()\n",
    "\n",
    "# Add documents\n",
    "db.add_document(\"This is a document about artificial intelligence.\")\n",
    "db.add_document(\"Vector databases are useful for similarity search.\")\n",
    "\n",
    "# Add multiple documents at once\n",
    "db.add_documents([\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"Embedding models convert text to vectors.\",\n",
    "    \"FAISS is a library for efficient similarity search.\"\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633731fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55d546a54a847b0bc6f77d1a49dd1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('This is a document about artificial intelligence.', np.float32(0.73847854)),\n",
       " ('FAISS is a library for efficient similarity search.',\n",
       "  np.float32(0.64280427)),\n",
       " ('Python is a popular programming language.', np.float32(0.60480684))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = db.search(\"How do AI systems work specifically with FAISS?\", k=3)\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
