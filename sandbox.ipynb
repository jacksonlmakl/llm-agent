{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040f4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/llm-agent/env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-05-14 15:33:16,192 - huggingface_hub._login - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-05-14 15:33:16,193 - llm - INFO - Successfully authenticated with Hugging Face\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of the optimized LLM Model class.\n",
    "\n",
    "This script demonstrates how to use the Model class for text generation\n",
    "with different configurations including chat-based generation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from llm import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a62482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 15:33:16,200 - llm - INFO - Initializing model: meta-llama/Llama-3.2-3B-Instruct\n",
      "2025-05-14 15:33:16,220 - llm - INFO - Using device: mps\n",
      "2025-05-14 15:33:16,467 - llm - INFO - Pad token not found, using EOS token as pad token\n",
      "2025-05-14 15:33:16,467 - llm - INFO - Tokenizer loaded: PreTrainedTokenizerFast\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c6367571714467963da6d9d6dc9e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 15:33:26,958 - llm - INFO - Model loaded: LlamaForCausalLM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(\"meta-llama/Llama-3.2-3B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4593fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackson.makl@dataiku.com/llm-agent/env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:698: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `1.5` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, me hearty! Here be a swashbucklin' poem fer ye:\n",
      "\n",
      "Oh, the ocean's roar doth echo through me soul,\n",
      "A callin' o' adventure, makin' me whole.\n",
      "Me heart beats fast, me spirit starts to soar,\n",
      "As I set sail on the seven seas once more.\n",
      "\n",
      "The wind in me hair, the spray upon me face,\n",
      "I feel alive, and ready for the pace.\n",
      "Me trusty cutlass by me side, sharp as can be,\n",
      "Ready to battle any sea monster that dares come near me!\n",
      "\n",
      "The sun sets low, paintin' the sky with gold,\n",
      "Castin' shadows dark, where legends unfold.\n",
      "I dream of treasure chests overflowin' with riches fine,\n",
      "And the thrill o' discovery, that only the sea divine.\n",
      "\n",
      "So hoist the sails, me hearties, let's set sail today,\n",
      "For adventure calls, and we'll find our way!\n",
      "We'll brave the waves, and ride out every storm,\n",
      "Together forever, me mateys, we'll chart our form!\n",
      "\n",
      "Yarrr! How didst thou enjoy it?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant who speaks like a pirate.\"},\n",
    "]\n",
    "\n",
    "response = model.generate(\n",
    "    prompt=\"Write a poem\",\n",
    "    max_new_tokens=450,\n",
    "    temperature=0.9,\n",
    "    typical_p=.9,\n",
    "    length_penalty=1.5,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bbb66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have a huge library with an infinite number of books, each representing a possible solution to a complex problem. In classical computers, we would need to look at each book one by one and check if it's the correct answer.\n",
      "\n",
      "Quantum computers work differently. They're like super-powerful librarians who can look at ALL the books simultaneously using special powers called \"qubits\" (quantum bits). This allows them to find answers much faster than classical computers for certain types of problems.\n",
      "\n",
      "Here are some key concepts:\n",
      "\n",
      "* **Qubits**: These are the building blocks of quantum information. Unlike regular computer chips that use 0s or 1s to process data, qubits can represent multiple states (like 0, 1, and both at the same time) all at once.\n",
      "* **Superposition**: Qubits exist in many states until they're measured, which is why they can try lots of possibilities simultaneously.\n",
      "* Quantum gates: These are operations that apply specific rules to manipulate qubits' states.\n",
      "* Entanglement: When two or more qubits interact, their properties become linked together, allowing them to affect each other even when separated.\n",
      "\n",
      "The potential benefits of quantum computing include solving extremely difficult mathematical problems efficiently, simulating real-world systems accurately, and breaking certain types encryption codes currently used online.\n",
      "\n",
      "However, there are also challenges, such as developing reliable control over these fragile quantum states and scaling up the technology while minimizing errors. Despite these hurdles, researchers continue exploring ways to harness the power of quantum mechanics to tackle groundbreaking computational tasks!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "direct_response = model.generate(\n",
    "    prompt=\"Explain quantum computing in simple terms\",\n",
    "    max_new_tokens=450,\n",
    "    temperature=0.7 \n",
    ")\n",
    "\n",
    "print(direct_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e524e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
